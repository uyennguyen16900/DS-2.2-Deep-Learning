{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()\n",
    "\n",
    "# flatten data\n",
    "# x_train = np.reshape(x_train, [-1, 28*28])\n",
    "# x_test = np.reshape(x_test, [-1, 28*28])\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "                      \n",
    "# normalize data by scaling them (0,1)\n",
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_test)\n",
    "\n",
    "# convert to one-hot vectors using the to_categorical function\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train.shape)\n",
    "nb_units = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b14e5dd2d53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_32_input to have 4 dimensions, but got array with shape (60000, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-956ded1770df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_32_input to have 4 dimensions, but got array with shape (60000, 784)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
